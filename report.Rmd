---
title: "Report"
author: "Elizabeth Serrano"
date: "2022-11-26"
output: html_document
---

```{r setup, include=FALSE}
 knitr::opts_chunk$set(echo = TRUE)

library(tidyverse) # has many data packages to tidy data
library(rmarkdown) # to create a dynamic document in R
library(knitr) #to generate rmarkdown files
library(dplyr) #to manipulate my data
library(tidyr) #to clean up messy data
library(ggplot2) #to display my data in graphs 
library(treemapify) #to convert my data to be used in a treemap
library(treemap) # to make a treemap
library(usmap) #to create a us map to determine where most of the sea food samples came from (US focused)
```

```{r - Cleaning up the Raw Data}
FishFraud <- read.csv("Fish Fraud Data CSV.csv") #loaded the csv file of the raw data into r 


TidyFishFraud <- select(FishFraud, -Fraud.map.category, -Notes, -repeat., -Species.Geographic.Range, -Amount.of.processing, -Website, -Reference, -In.fraud.map., -In.endnote., -Fraud.Map.ID., -Potentially.Farmed., -farmed.n, -X, -X.1, -X.2, -X.3, -X.4, -X.5, -X.6, -X.7, -X.8) 

#i removed these columns as i determined that they were either irrelevant to what I wanted to asnwer, or there wasnt enough data in these columns to do anything with it 

TidyFishFraud <- filter(
  TidyFishFraud, 
  !is.na(Study.number)
) #here I am removing all the rows that contain an NA under the study.number column. 

TidyFishFraud[943,3] <- 22
#replaced a cell in the 943 row, 3rd column with the value of 22 when it was previously "22 actual"

glimpse(TidyFishFraud)


```
```{r what places where the fish mostly retrieved from?}
#I want to know where most of the fish was sampled from. So I am going to need to create a data frame that takes the studies columns and the locations of the purchased fish 
FraudLocation <-select(TidyFishFraud, Study.number, Study.authors...year, Sampling.Area..where.retail.fish.purchased.)
#This is data frame showing all the studies and all the places the fish from those studies were bought from (location) 
# Since most of this sea food was sampled within the US, I am going to try to standardize these entries to show the locations (states within the US) where the seafood came from. 

#Purchased within US but exact state is undetermined. 
FraudLocation$Sampling.Area..where.retail.fish.purchased.[FraudLocation$Sampling.Area..where.retail.fish.purchased.== "USA"] <- "USA (state undetermined)"

FraudLocation$Sampling.Area..where.retail.fish.purchased.[FraudLocation$Sampling.Area..where.retail.fish.purchased.== "US"] <- "USA (state undetermined)"

FraudLocation$Sampling.Area..where.retail.fish.purchased.[FraudLocation$Sampling.Area..where.retail.fish.purchased.== "21 states"] <- "USA (state undetermined)"

FraudLocation$Sampling.Area..where.retail.fish.purchased.[FraudLocation$Sampling.Area..where.retail.fish.purchased.== "United States"] <- "USA (state undetermined)"

FraudLocation$Sampling.Area..where.retail.fish.purchased.[FraudLocation$Sampling.Area..where.retail.fish.purchased.== "medium size city in SE US"] <- "USA (state undetermined)"

#There are some samples that dont have any location mentioned. These are empty strings and I will replace them with NA. 
FraudLocation[FraudLocation == ''] <- NA

#Replace the NA's with an Undetermined Location 
FraudLocation[is.na(FraudLocation)] <- "Undetermined"

#Here I will replace the locations to show the state where the samples were retrieved from 

#New York
FraudLocation[FraudLocation == "NY"] <- "New York"
FraudLocation[FraudLocation == "New York City "] <- "New York"
FraudLocation[FraudLocation == "New York City"] <- "New York"
FraudLocation[FraudLocation == "New Bedford, MA (company)"] <- "New York"
FraudLocation[FraudLocation == "NYC"] <- "New York"
FraudLocation[FraudLocation == "New York, New York"] <- "New York"

#Massachusetts
FraudLocation[FraudLocation == "Boston, MA"] <- "Massachusetts"
FraudLocation[FraudLocation == "MA (company)"] <- "Massachusetts"
FraudLocation[FraudLocation == "MA (company)"] <- "Massachusetts"

#Washington 
FraudLocation[FraudLocation == "W.Washington State"] <- "Washington"
FraudLocation[FraudLocation == "Seattle, WA"] <- "Washington"
FraudLocation[FraudLocation == "Bellingham, WA"] <- "Washington"
FraudLocation[FraudLocation == "Washington, DC "] <- "Washington"
FraudLocation[FraudLocation == "Washington, DC"] <- "Washington"

#California
FraudLocation[FraudLocation == "Los Angeles"] <- "California"
FraudLocation[FraudLocation == "Los Angeles, CA, USA"] <- "California"
FraudLocation[FraudLocation == "California, Los Angeles"] <- "California"
FraudLocation[FraudLocation == "California, San Francisco"] <- "California"
FraudLocation[FraudLocation == "California, Oakland"] <- "California"
FraudLocation[FraudLocation == "California, San Jose"] <- "California"
FraudLocation[FraudLocation == "California, Sausalito"] <- "California"
FraudLocation[FraudLocation == "California, San Rafael"] <- "California"
FraudLocation[FraudLocation == "California, Walnut Creek"] <- "California"
FraudLocation[FraudLocation == "California, Orange County"] <- "California"
FraudLocation[FraudLocation == "Santa Cruz, CA"] <- "California"
FraudLocation[FraudLocation == "San Diego"] <- "California"
FraudLocation[FraudLocation == "Santa Monica, CA (company), CA (purchaser)"] <- "California"
FraudLocation[FraudLocation == "San Francisco, CA"] <- "California"
FraudLocation[FraudLocation == "Sentencing in Los Angeles California"] <- "California"

#Florida 
FraudLocation[FraudLocation == "Florida - Jacksonville area"] <- "Florida"
FraudLocation[FraudLocation == "Tampa, FL"] <- "Florida"
FraudLocation[FraudLocation == "Tampa, St. Petersburg, FL"] <- "Florida"
FraudLocation[FraudLocation == "Panama City, FL"] <- "Florida"
FraudLocation[FraudLocation == "Hialeah, FL"] <- "Florida"
FraudLocation[FraudLocation == "Volusia county, FL"] <- "Florida"
FraudLocation[FraudLocation == "Fort Myers, Florida"] <- "Florida"
FraudLocation[FraudLocation == "Tallahassee, Florida"] <- "Florida"
FraudLocation[FraudLocation == "Tampa Bay, Florida"] <- "Florida"
FraudLocation[FraudLocation == "North Miami Beach, FL"] <- "Florida"
FraudLocation[FraudLocation == "Miami, FL (company)"] <- "Florida"
FraudLocation[FraudLocation == "Tampa, FL (company)"] <- "Florida"
FraudLocation[FraudLocation == "FL (company)"] <- "Florida"
FraudLocation[FraudLocation == "Hialeah, FL (company)"] <- "Florida"
FraudLocation[FraudLocation == "FL (purchaser)"] <- "Florida"

#Missouri 
FraudLocation[FraudLocation == "St. Louis, MO"] <- "Missouri"
FraudLocation[FraudLocation == "Kansas City, MO"] <- "Missouri"

#Georgia
FraudLocation[FraudLocation == "Atlanta, GA"] <- "Georgia"
FraudLocation[FraudLocation == "GA (company)"] <- "Georgia"
FraudLocation[FraudLocation == "Savannah, GA"] <- "Georgia"

#Maryland 
FraudLocation[FraudLocation == "Baltimore, MD"] <- "Maryland"

#Arizona 
FraudLocation[FraudLocation == "Phoenix,AZ"] <- "Arizona"

#Illinois 
FraudLocation[FraudLocation == "Chicago, IL"] <- "Illinois"
FraudLocation[FraudLocation == "Addison, IL (company)"] <- "Illinois"
FraudLocation[FraudLocation == "Oak Park, IL"] <- "Illinois"
FraudLocation[FraudLocation == "Chicago and suburbs"] <- "Illinois"

#North Carolina 
FraudLocation[FraudLocation == "Gastonia, NC"] <- "North Carolina"

#Virginia 
FraudLocation[FraudLocation == "VA (company)"] <- "Virginia"



#Some values have in the Sample Area column mention 2+ states. I am going to repeat those rows by the number of states mentioned and replace the values with each state mentioned.

#Study 1
Study1 <-FraudLocation %>% slice(rep(1,2)) #Replicated 1st study twice
Study1[1,3] <- "USA (state undetermined)"
Study1[2,3] <- "Canada"  

#Study 3
Study3 <- FraudLocation %>% slice(rep(17,8)) #Replicated 3rd study 8 times
Study3[1,3] <-"Delaware"
Study3[2,3]<- "Florida"
Study3[3,3]<- "Illinois"
Study3[4,3]<- "Massachusetts"
Study3[5,3]<- "New York"
Study3[6,3]<- "North Carolina"
Study3[7,3]<- "South Carolina"
Study3[8,3]<- "Wisconsin"  #Each state is now represented in the 3rd study 

#Study 6
#two rows x 5 states = 10 repeats
Study6<-FraudLocation %>% slice(rep(34,10))
#Each two rows will have the same state name out of the 5 states mentioned. 
Study6[1:2, 3]<- "California"
Study6[3:4, 3]<- "New York"
Study6[5:6, 3]<- "North Carolina"
Study6[7:8, 3]<- "Missouri"
Study6[9:10, 3]<- "Florida"

#Study 9
#6 rows x 2 states = 12 repeats
Study9<-FraudLocation %>% slice(rep(59,12))
#I will repeat the same process here. 
Study9[1:6, 3]<-"Colorado"
Study9[7:12, 3]<-"New York"


#Study 10
#3 rows x 2 states = 6 repeats
Study10<-FraudLocation %>% slice(rep(65,6))
Study10[1:3,3]<- "Florida"
Study10[4:6,3]<- "Alabama"

#Study 12
#2 rows x 2 states
Study12<-FraudLocation %>% slice(rep(79,4))
Study12[1:2,3] <-"California"
Study12[3:4,3] <-"Washington"

#Study 17
#4 rows x 10 states
Study17<- FraudLocation %>% slice(rep(166,40))
Study17[1:4,3] <- "California"
Study17[5:8,3]<- "Arizona"
Study17[9:12,3]<- "Texas"
Study17[13:16,3]<- "North Carolina"
Study17[17:20,3]<- "South Carolina"
Study17[21:24,3]<- "Tennessee"
Study17[25:28,3]<- "Lousiana"
Study17[29:32,3]<- "Florida"
Study17[33:36,3]<- "Maryland"
Study17[37:40,3]<- "Massachusetts"


#Study 18
#14 rows x 3 states 
Study18<- FraudLocation %>% slice(rep(170,42))
Study18[1:14,3]<- "New York"
Study18[15:28,3]<-"Connecticut"
Study18[29:42,3]<-"New Jersey"

#Study 63
#5 rows x 4 states 
Study63<- FraudLocation %>% slice(rep(234,20))
Study63[1:5,3] <- "New York"
Study63[6:10,3] <- "Massachusetts"
Study63[11:15,3]<- "Pennsylvania"
Study63[16:20,3]<- "Washington"

#Study 100
#5 rows x 2 states 
Study100<- FraudLocation %>% slice(rep(315,10))
Study100[1:5,3]<- "Lousiana"
Study100[6:10,3] <- "Florida"

#Study 102
#17 rows x 4 states 
Study102<- FraudLocation %>% slice(rep(332,68))
Study102[1:17,3] <- "New York"
Study102[18:34,3]<- "New Jersey"
Study102[35:51,3]<- "Massachusetts"
Study102[52:68,3]<-"Florida"


#Study 121
# 401 rows x 12 states 
Study121<- FraudLocation %>% slice(rep(384,4812))
Study121[1:401,3] <-"Georgia"
Study121[402:802,3]<- "Texas"
Study121[803:1203,3]<-  "Massachusetts"
Study121[1204:1604,3]<- "Illinois"
Study121[1605:2005,3]<- "Colorado"
Study121[2006:2406,3]<- "Missouri"
Study121[2407:2807,3]<- "California"
Study121[2808:3208,3]<- "Florida"
Study121[3209:3609,3]<- "New York"
Study121[3610:4010,3]<- "Pennsylvania"
Study121[4011:4411,3]<- "Oregon"
Study121[4412:4812,3]<- "Washington"


#Study 122
#44 rows x 8 states 
Study122 <- FraudLocation %>% slice(rep(785,352))
Study122[1:44,3]<- "Oregon"
Study122[45:88,3] <- "New York"
Study122[89:132,3]<- "Washington"
Study122[133:176,3]<- "Florida"
Study122[177:220,3]<- "Alabama"
Study122[221:264,3]<- "Mississippi"
Study122[265:308,3]<- "Louisiana"
Study122[309:352,3]<- "Texas"


#Study 123
#34 rows x 2 states
Study123<- FraudLocation %>% slice(rep(829,68))
Study123[1:34,3]<- "Maryland"
Study123[35:68,3]<- "Washington"

#Study 145
#2 rows x 2 states 
Study145<- FraudLocation %>% slice(rep(866,4))
Study145[1:2,3] <- "California"
Study145[3:4,3] <- "New York"

#Study 147
#10 rows x 3 states
Study147<- FraudLocation %>% slice(rep(870,30))
Study147[1:10,3]<- "California"
Study147[11:20,3] <- "Texas"
Study147[21:30, 3] <- "New York"


#Study 150
#1 row x 2 states 
Study150<- FraudLocation %>% slice(rep(887,2))
Study150[1,3]<- "North Carolina"
Study150[2,3] <-  "Louisiana"

#Study 151
#1 row x 2 states 
Study151 <- FraudLocation %>% slice(rep(888,2))
Study151[1,3]<- "Texas"
Study151[2,3] <- "Louisiana"

#Study 154
#1 row x 3 states
Study154<- FraudLocation %>% slice(rep(896,3))
Study154[1,3]<- "Virginia"
Study154[2,3]<- "Delaware"
Study154[3,3]<- "North Carolina"

#Study 160
#1 row x 3 states
Study160<- FraudLocation %>% slice(rep(907,3))
Study160[1,3]<- "Washington"
Study160[2,3]<- "Utah"
Study160[3,3]<- "Texas"

```

For the studies that mention 2+ states in a single cell, I am going to remove these rows from the FraudLocation data frame until there is only one instance of each row and crate a new data frame called TestLocation. I only leave one instance of the rows with multiple states in a cell so that when I do a join, i can ID by the study number. If i remove all the rows, then there wouldn't be anything for me to ID by. 

Update: Im just going to remove all the instacnes where there ae 2+ states and instead of doing a join, im going to do an rbind(). That way, all the rows are joined together without issue. 
```{r}
#Removal
FraudLocation <- FraudLocation[-c(1,17,34,35,59:67,79,80,166:183,234:238,315:319,332:348,384:862,866,867,870:872,874:880,887,888,896,907),]

#rbind the studies that were removed 
FraudLocation<-rbind(FraudLocation, Study1, Study3, Study6, Study9, Study10, Study12, 
                     Study17, Study18, Study63, Study100, Study102, Study121, Study122,
                     Study123, Study145, Study147, Study150, Study151, Study154, Study160)
#Arrange by aescending order 
FraudLocation<-arrange(FraudLocation, Study.number)

#count the number of instances for each location and make it into its own data frame so I can use that for a plot (unsure which one to use yet)
FraudLocation %>% count(Sampling.Area..where.retail.fish.purchased.)->Location_Count
colnames(Location_Count)[1]= "Samping Area"
colnames(Location_Count)[2] = "Total Samples"

#Where were most of the samples gathered in the US? 
#State map 

#remove the rows that dont specify a US state 
Location_USOnly<- Location_Count[-c(5,27,28),]
#rename second column to total
colnames(Location_USOnly)[2]="Total"
colnames(Location_USOnly)[1] = "state"

plot_usmap(data= Location_USOnly, values= "Total", color="black") +
  scale_fill_continuous( 
    low= "white", high= "Blue", name = "Seafood Samples Collected") + 
  theme(legend.position = "right")
#The gray portions are states where samples were not collected

#Most of the samples were collected within the united states, with the exception of Canada (which only account for two samples). I choose to leave out the undertermined column as i can't determine the source of the samples. I also choose to leave out the USA (undetermined) column as we cannot determine the exact state where those samples came from. Regardless, it is clear that most of the samples within this data set did some from the united states. and from the states that were mentioned, we can see that many of those samples came from *insert names of states here*. The reasons for this can vary but I suspect because its easier to have access to fish given that these states are where there are many harbors and fisheries (they are on a coast).




```

```{r - total samples , total mislabled samples, & % mislabled}
#turn all the values in the numbe of samples column into a vector
Total_Samples<- TidyFishFraud$Number.of.samples
# I removed all the empty strings, and all the cases where the number of samples was "not specified". 
Total_Samples<- Total_Samples[Total_Samples!=""]
Total_Samples<- Total_Samples[Total_Samples!=" "]
Total_Samples<-Total_Samples[Total_Samples!="not specified"]
#Turn the strings into integer values
Total_Samples <-Total_Samples %>% strtoi(base=0L) 
#find the sum of the samples, while exlcuding NAs
Total_Samples<- sum(Total_Samples,na.rm=TRUE)

#turn all vaues in the mislabled samples column into a vector
Mislabled_Samples<- TidyFishFraud$Number.of.mislabeled.samples
#remove all empty strings, and all cases where the number of mislabled samples was "not specified"
Mislabled_Samples <-Mislabled_Samples[Mislabled_Samples!=""]
Mislabled_Samples <-Mislabled_Samples[Mislabled_Samples!=" "]
Mislabled_Samples <-Mislabled_Samples[Mislabled_Samples!="not specified"]
Mislabled_Samples<-Mislabled_Samples %>% strtoi(base=0L) 
Mislabled_Samples<- sum(Mislabled_Samples,na.rm=TRUE)

Percentage_Mislabled <- (Mislabled_Samples/Total_Samples)*100


```



```{r confirmed fraud}
#turn into vector, only want the fraud mislabeling column
FraudMislabeling_Col<- TidyFishFraud$Fraud.mislabeling.
#count total number of things in vector 
Total_FraudMislabeling<-length(FraudMislabeling_Col)
#only want the cells that contain "yes" and pipe that into the length function
Yes_ConfirmedFraud<- FraudMislabeling_Col[FraudMislabeling_Col=="yes"] %>% length()

Percent_Confirmed <-(Yes_ConfirmedFraud/Total_FraudMislabeling)*100







FraudMislabeling_Col<- TidyFishFraud$Fraud.mislabeling.

Total_FraudMislabeling<-length(FraudMislabeling_Col)

Yes_ConfirmedFraud<- FraudMislabeling_Col[FraudMislabeling_Col=="yes"] %>% length()

Percent_Confirmed <-(Yes_ConfirmedFraud/Total_FraudMislabeling)*100


```



```{r bar graph to show the percentage of labels that match vs do not match }
#variables used seafood.type (label) and species group (actual fish)
#wont use the label column because it gets very specifc with names/species, such as white tuna,yellow fish tuna, southern blue fish tuna. I just want to know the % of labels that match, at the very least, the species of fish/seafood that is being sold. 
#new data frame for the this question
Match <- select(TidyFishFraud, Study.number, Study.authors...year,seafood.type, Species.group)
#turn both columns into lowercase
Match$seafood.type <-tolower(Match$seafood.type)
Match$Species.group <-tolower(Match$Species.group)
#now we compare the two columns and create a new column to be added to the match #data frame
Match$Label_Match<- ifelse(Match$seafood.type==Match$Species.group, "Yes",
                           ifelse(Match$seafood.type!= Match$Species.group,"No","NA")) 
#Make into bar chart
BarMatch<-ggplot(Match, aes(Label_Match, fill=Label_Match))
BarMatch+geom_bar()+ 
  labs(title="Match Frequency in Fish Samples", 
       subtitle="How many labels match the fish being sold?")



```

```{r what are the top 5 seafood groups that get mislabeled? }
#Take the seafood group column and the label_match column (no), and from there #find the top 5 
Top5<- filter(
  Match, 
  Label_Match=="No"
)
#rename second column 
colnames(Top5)[2]="Total"
#count the total number of seafood types 
Top5 %>% count(seafood.type) ->Top5
#IDK how to get the top5, ive tried 

#for now, i will select the top 5 manually and make a table like that 
Top5Temp<- data.frame(seafood.type=c("snapper", "tuna", "caviar,sturgeon", "grouper", "cod"),
                      Total=c(221, 106, 57, 55,33))

```

```{r dot plot ICUN conservation status of the fish }
#new data frame for the conservation 
Conservation<- select(
  TidyFishFraud, 
  Study.number, 
  IUCN.Conservation.Status
)
#replace empty strings with "undetermined" 
Conservation[Conservation ==""] <- "undetermined"
Conservation %>% count(IUCN.Conservation.Status) -> ConservationCount
#rename column to total 
colnames(ConservationCount)[2]="Total"
#make dot plot 
ggplot(ConservationCount, aes(x=IUCN.Conservation.Status, y=Total)) + 
  geom_point(col="tomato2", size=3)+
  geom_segment(aes(x=IUCN.Conservation.Status,
                   xend=IUCN.Conservation.Status,
                   y=min(Total),
                   yend=max(Total)),
               linetype="dashed", 
               size=0.1) +
  labs(title='IUCN Conservation Status of the Samples',
       caption="Key: NT = Near Threatened; VU = Vulnerable; EN=Endangered; 
       CR= Critically Endangered; NE= Not Evaluated; LS = Least Concern; 
       DD = Data Deficient; Undetermined = Status was not designated")

```

```{r risks associated with fish fraud }
#data frame for risks to then make it into an ordered bar chart 
Risks<- select(TidyFishFraud, Study.number, Health.Risk)
#empty strings turn into "undertermined"
Risks[Risks==""]<-"undetermined"
#na's will be "No Risk"
Risks[Risks=="na"]<- "No Risk"
#Any cell that has 2+ risks will turn into "Combination"
Risks[str_detect(Risks, pattern = " [+]* ")]
Risks[Risks=="NT+P+H+M"]<-"Combination"
Risks[Risks=="P+EC"]<- "Combination"
Risks[Risks=="H+NT"]<- "Combination"
Risks[Risks=="EC+AqD"]<- "Combination"
Risks[Risks=="EC+AqD+P"]<- "Combination"
Risks[Risks=="EC+AqD"]<- "Combination"
Risks[Risks=="Ec+AqD+NT+H"]<-"Combination"
Risks[Risks=="M+H"]<- "Combination"
Risks[Risks=="M+H+P"]<- "Combination"
Risks[Risks=="M+H+P+NT+EC"]<- "Combination"
Risks[Risks=="P+NT+EC"]<- "Combination"
Risks[Risks=="P+NT"]<- "Combination"
Risks[Risks=="P+H"]<- "Combination"
Risks[Risks=="P+EC+AqD"]<- "Combination"
Risks[Risks=="NT+H"]<- "Combination"
Risks[Risks=="M+P"]<- "Combination"
Risks[Risks=="EC+P"]<- "Combination"
#count
Risks %>%  count(Health.Risk) -> Risks2
#rename column 2
colnames(Risks2)[2]<- "Total"
#bar graph time 
ggplot(Risks2, aes(x=Health.Risk, y=Total)) + 
  geom_bar(stat="identity", width=.5, fill= "tomato3") + 
  labs( title= 'Health Risks Identified in Mislabeled Samples',
        caption= "H = Histamine ; P = Parasites; NT = Natural Toxins; M = Mercury; 
        EC = Environmental Chemicals; AqD= Aquaculture Drugs ")


```

```{r Where were most of the samples acquired from Supply Chain}

# im going to make a new data frame specifically for this graph because Im going #to have to alter # it to fit the treemap
TreeData<- select(TidyFishFraud, Study.number, Study.authors...year, Point.in.supply.chain)
# replace the empty strings with "undetermined" as a category
TreeData[TreeData==''] <- "undetermined"
TreeData[TreeData=="retail"]<-"Retail (undetermined)"
#There are some points in the supply chain that mention more than one location, I am going to #remove these studies from the TreeData df, duplicate their rows to show the # of instances that 
# each location is mentioned and then use an rbind to join them back to the Tree Data df

#Study 15 
#85 rows x 3 location = 255 repeats
T_Study15<-TreeData %>% slice(rep(81,255))
T_Study15[1:85, 3]<- "retail, grocery"
T_Study15[86:170, 3]<- "retail, restuarant"
T_Study15[171:255, 3]<- "retail, market"

#Study 18 
T_Study18 <- TreeData %>% slice(rep(170,28))
T_Study18[1:14,3] <- "retail, grocery"
T_Study18[15:28,3] <- "retail, restaurant"

#Study 20 
T_Study20<- TreeData %>% slice(rep(185, 22))
T_Study20[1:11,3]<- "retail, grocery"
T_Study20[12:22,3] <- "retail, restaurant"

#Study 66
T_Study66<- TreeData %>% slice(rep(239,4))
T_Study66[1:2,3]<- "Retail (undetermined)"
T_Study66[3:4,3] <- "Wholesale"

#Study85 
T_Study85<- TreeData %>% slice(rep(266,2))
T_Study85[1,3]<- "Retail (undetermined)"
T_Study85[2,3]<- "Wholesale"

#Study 86 
T_Study86 <- TreeData %>% slice(rep(267,52))
T_Study86[1:26,3]<- "retail"
T_Study86[27:52,3]<- "import"

#Study 91
T_Study91 <- TreeData %>% slice(rep(296,2))
T_Study91[1,3]<- "retail, grocery"
T_Study91[2,3]<- "distributor"

#one line in study 97 
T_Study97 <- TreeData %>% slice(rep(298, 2))
T_Study97[1,3] <- "retail, grocery"
T_Study97[2,3] <- "retail, restaurant"

#Study 109
T_Study109<- TreeData %>% slice(rep(369,4))
T_Study109[1:2,3]<- "distributor"
T_Study109[3:4,3]<- "import"

#Study147
T_Study147<- TreeData %>% slice(rep(873,2))
T_Study147[1,3]<- "Retail (undetermined)"
T_Study147[2,3]<- "Wholesale"

#Study 161
T_Study161<- TreeData %>% slice(rep(908,2))
T_Study161[1,3]<- "Retail (undetermined)"
T_Study161[2,3]<- "Export"

#Study 163 
T_Study163 <-TreeData %>% slice(rep(911,2))
T_Study163[1,3]<- "Retail (undetermined)"
T_Study163[2,3] <- "Wholesale"

#Study 168 
T_Study168<- TreeData %>% slice(rep(918,2))
T_Study168[1,3]<- "Retail / Fish Dealer"
T_Study168[2,3]<- "Wholesaler"

#I am now going to remove all the studies that have 2+ point in supply chain locations 
TreeData<- TreeData[-c(81:165,170:183,185:195,239,240,266:292,296,298,369,370,873,911,908,918),]

#rbind all the studies to the TreeData df 
TreeData<- rbind(TreeData, T_Study15, T_Study18, T_Study20, T_Study66, T_Study85, T_Study86,
                 T_Study91, T_Study97, T_Study109, T_Study147, T_Study161, T_Study163, T_Study168)

#There are some NAs for the study number and author columns but that doesnt matter anyways for our #purposes right now 

#duplicate the point in supply chain column so i can alter the second column easier
TreeData$SC.Sub.Group<- TreeData$Point.in.supply.chain
colnames(TreeData)[3]="Point in SC"
colnames(TreeData)[4]= "SC Sub Group"

#clean up the data frame 
TreeData[TreeData == "undetermined"] <- "Undetermined"
TreeData[TreeData== "retail"]<- "Retail"
TreeData[TreeData=="import"]<- "Import"
TreeData[TreeData=="importer"]<- "Import"
TreeData[TreeData=="restaurant"]<- "Restaurant"
TreeData[TreeData=="distributor"]<- "Distributor"
TreeData[TreeData=="wholesale"]<- "Wholesale"
TreeData[TreeData=="packager"]<- "Packager"
TreeData[TreeData=="shipping"]<- "Shipping"
TreeData[TreeData=="processor"]<- "Processor"

#order the row index numbers
row.names(TreeData)<- NULL

TreeData[1,3]<- "Retail"
TreeData[1,4]<-"Undetermined"
TreeData[17:19,3]<- "Retail"
TreeData[17:19,4]<- "Undetermined"
TreeData[20:64,3]<- "Retail"
TreeData[20:32,4]<- "Fish Dealer"
TreeData[33:64,4]<- "Undetermined"
TreeData[68:85,3]<- "Retail"
TreeData[68:85,4]<- "Undetermined"
TreeData[88:151,3]<- "Retail"
TreeData[88:119,4]<- "Undetermined"
TreeData[120:123,4]<- "Restaurant"
TreeData[124:136,4]<- "Undetermined"
TreeData[137:141,4]<- "Restaurant"
TreeData[142:150,4]<- "Market"
TreeData[151,4]<- "Restaurant"
TreeData[156:157,3]<- "Retail"
TreeData[156:157,4]<- "Undetermined"
TreeData[161:227,3]<- "Retail"
TreeData[161:227,4]<- "Undetermined"
TreeData[235:239,3]<- "Retail"
TreeData[235:239,4]<- "Restaurant"
TreeData[241:722,3]<- "Retail"
TreeData[241:722,4]<- "Undetermined"
TreeData[723:736,3]<- "Retail"
TreeData[741:742,3]<- "Retail"
TreeData[770:771,3]<- "Retail"
TreeData[770:771,4]<- "Undetermined"
TreeData[773:796,3]<- "Retail"
TreeData[780,4]<- "Undetermined"
TreeData[783:788,4]<- "Undetermined"
TreeData[789:794,4]<- "Restaurant"
TreeData[795:796,4]<- "Undetermined"
TreeData[798,3]<- "Retail"
TreeData[831:1137,3]<- "Retail"
TreeData[831:915,4]<- "Grocery"
TreeData[916:1000,4]<- "Restaurant"
TreeData[1001:1085,4]<- "Market"
TreeData[1086:1099,4]<- "Grocery"
TreeData[1100:1113,4]<- "Restaurant"
TreeData[1114:1124,4]<- "Grocery"
TreeData[1125:1135,4]<- "Restaurant"
TreeData[1136:1137,4]<- "Undetermined"
TreeData[1140,3]<- "Retail"
TreeData[1140,4]<- "Undetermined"
TreeData[1194,3]<- "Retail"
TreeData[1194,4]<- "Grocery"
TreeData[1196:1197,3]<- "Retail"
TreeData[1196,4]<- "Grocery"
TreeData[1197,4]<- "Restaurant"
TreeData[1202,3]<- "Retail"
TreeData[1202,4]<- "Undetermined"
TreeData[1204,3]<- "Retail"
TreeData[1204,4]<- "Undetermined"
TreeData[1206,3]<- "Retail"
TreeData[1206,4]<- "Undetermined"
TreeData[1208,3]<- "Retail"
TreeData[1208,4]<- "Fish Dealer"
TreeData[1142:1167,4]<- "Undetermined"

#add numerical column 
TreeData$Value<- 1

treemap(TreeData,
        index= c("Point in SC","SC Sub Group"),
        vSize= "Value",
        type= "index",
        title= "Location of the Samples Acquired: Supply Chain",
        fontsize.title = 14
        )

```

